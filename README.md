# etl-volumetria-pyspark-parquet

**Pipeline ETL modular em PySpark para processar grandes volumes de dados**  
geraÃ§Ã£o de dados sinteticos, transformaÃ§Ã£o de dados, particionamento e escrita em Parquet com boas prÃ¡ticas de engenharia de dados.

---

## ğŸ› ï¸ Tecnologias

- **PySpark** â€“ processamento distribuÃ­do  
- **Parquet** â€“ formato colunar particionado por data  
- **Python 3.7+** â€“ estrutura de projeto, configuraÃ§Ã£o e testes  
- **pytest** â€“ testes unitÃ¡rios das transformaÃ§Ãµes
